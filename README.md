# 🧠 Deep Learning for NLP  
**March 2024 - April 2024**  

🚀 **NLP | Deep Learning | Machine Translation**  

## 📌 Project Overview  
This project explores **deep learning techniques for NLP tasks**, covering:  
- **CNN for Text Classification**: Used **convolutional neural networks (CNN)** to classify sentences.  
- **Sequence-to-Sequence Machine Translation**: Implemented **Seq2Seq models** and evaluated performance using **BLEU scores**.  
- **GPT-2 Fine-Tuning & Feature Extraction**: Fine-tuned **GPT-2** and compared **classification performance** with and without fine-tuning.  

## 🏗️ Tech Stack  
✅ **Languages & Libraries**: Python, TensorFlow, PyTorch, Scikit-learn, NLTK, Hugging Face Transformers  
✅ **NLP Models**: CNN-based classifiers, Seq2Seq models, GPT-2  
✅ **Evaluation Metrics**: BLEU score, Accuracy, AUROC, Precision, Recall  
✅ **Data Processing**: Tokenization, GloVe embeddings, Data Augmentation  

## 📊 Key Highlights  
📌 **Built and evaluated CNN-based text classification models.**  
📌 **Implemented sequence-to-sequence models for machine translation.**  
📌 **Fine-tuned GPT-2 for language modeling and classification.**  

## 🔧 Future Work  
🔜 Experimenting with **Transformer-based models** like T5 and BART.  
🔜 Improving BLEU scores using **attention-based models**.  

## 🚀 Running the Project  
1️⃣ Open **Google Colab** or **Jupyter Notebook**.  
2️⃣ Upload the following notebooks and run them in order:  
   - `CNN text classification.ipynb` → for CNN-based Text Classification  
   - `Seq2Seq MT.ipynb` → for Sequence-to-Sequence Machine Translation  
   - `GPT LM-3.ipynb` → for GPT-2 Fine-Tuning & Evaluation  
   - `Experiments.ipynb` → for Additional NLP Experiments  

